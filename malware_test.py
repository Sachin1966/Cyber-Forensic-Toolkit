import pandas as pd
import numpy as np
import joblib
import os
import sys
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix

# ---------------------------------------
# Configuration
# ---------------------------------------
MODELS_DIR = "./models"
TEST_FILE_DEFAULT = "./dataset/test.csv" # Default test file if none provided

# ---------------------------------------
# Helper Functions (Reused from training)
# ---------------------------------------
LABEL_MAP = {
    "benign": 0, "legit": 0, "legitimate": 0, "normal": 0, "good": 0, "0": 0, "safe": 0,
    "malware": 1, "attack": 1, "malicious": 1, "bad": 1, "1": 1, "virus": 1,
    "trojan": 1, "ransomware": 1, "spyware": 1, "adware": 1,
    "exploits": 1, "fuzzers": 1, "analysis": 1, "reconnaissance": 1,
    "backdoor": 1, "ddos": 1, "dos": 1, "generic": 1, "shellcode": 1,
    "worms": 1, "ftp-patator": 1, "ssh-patator": 1, "infiltration": 1,
    "botnet": 1, "bruteforce": 1, "portscan": 1
}

def clean_malware_labels(series):
    s = series.astype(str).str.lower().str.strip()
    return s.map(LABEL_MAP)

def load_and_preprocess(filepath, feature_names):
    print(f"\nProcessing {filepath}...")
    
    # 1. Load
    try:
        df = pd.read_csv(filepath, sep=None, engine='python', low_memory=False)
    except:
        df = pd.read_csv(filepath, low_memory=False)
        
    print(f"✔ Loaded shape: {df.shape}")

    # 2. Handle Labels
    y_true = None
    label_candidates = [c for c in df.columns if any(k in c.lower() for k in
        ["label", "malware", "attack", "class", "category", "target", "type"])]
    
    if label_candidates:
        label_col = label_candidates[0]
        print(f"✔ Found label column: {label_col}")
        df["label"] = clean_malware_labels(df[label_col])
        df = df.dropna(subset=["label"])
        y_true = df["label"].astype(int)
        if label_col != "label":
            df.drop(columns=[label_col], inplace=True)
    else:
        print("⚠ No label column found. Will only perform prediction.")

    # 3. Force Numeric
    for col in df.columns:
        if col != "label":
            df[col] = pd.to_numeric(df[col], errors="coerce")
    
    # 4. Align Features
    # Create a DataFrame with the exact columns expected by the model
    # Initialize with 0s for missing features
    X_aligned = pd.DataFrame(0, index=df.index, columns=feature_names)
    
    # Fill in values for columns that exist in both
    common_cols = list(set(df.columns) & set(feature_names))
    X_aligned[common_cols] = df[common_cols]
    
    # Fill NaNs with 0
    X_aligned.fillna(0, inplace=True)
    
    return X_aligned, y_true

def test_model(test_file=None):
    # 1. Load Model Assets
    try:
        model = joblib.load(f"{MODELS_DIR}/malware_model.pkl")
        scaler = joblib.load(f"{MODELS_DIR}/malware_scaler.pkl")
        feature_names = joblib.load(f"{MODELS_DIR}/malware_features.pkl")
        print("✔ Model, Scaler, and Features loaded successfully.")
    except Exception as e:
        print(f"❌ Error loading model assets: {e}")
        print("Did you run malware_train.py first?")
        return

    # 2. Determine Test File
    if test_file is None:
        # Try to find a csv in dataset folder if not provided
        if os.path.exists(TEST_FILE_DEFAULT):
            test_file = TEST_FILE_DEFAULT
        else:
            # Look for any csv in dataset/
            dataset_dir = "./dataset"
            if os.path.exists(dataset_dir):
                for root, dirs, files in os.walk(dataset_dir):
                    for f in files:
                        if f.endswith(".csv"):
                            test_file = os.path.join(root, f)
                            break
    
    if not test_file or not os.path.exists(test_file):
        print("❌ No test file found. Please provide a CSV file path.")
        return

    # 3. Preprocess
    X, y_true = load_and_preprocess(test_file, feature_names)
    
    if X.empty:
        print("❌ No valid data to test.")
        return

    # 4. Scale
    print("Scaling data...")
    X_scaled = scaler.transform(X)

    # 5. Predict
    print("Predicting...")
    y_pred = model.predict(X_scaled)
    y_prob = model.predict_proba(X_scaled)[:, 1]

    # 6. Results
    print("\n============== TEST RESULTS ==============")
    print(f"File: {test_file}")
    print(f"Total Samples: {len(X)}")
    print(f"Predicted Malicious: {sum(y_pred)} ({sum(y_pred)/len(X):.1%})")
    print(f"Predicted Benign: {len(X)-sum(y_pred)}")
    
    if y_true is not None:
        print("\n--- Performance Metrics ---")
        acc = accuracy_score(y_true, y_pred)
        print(f"Accuracy: {acc:.4f}")
        print("\nConfusion Matrix:")
        print(confusion_matrix(y_true, y_pred))
        print("\nClassification Report:")
        print(classification_report(y_true, y_pred, target_names=["Benign", "Malicious"]))
    else:
        print("\n(No ground truth labels found, skipping metrics)")

    # Show some examples
    print("\n--- Sample Predictions ---")
    results = pd.DataFrame({
        "Confidence": y_prob,
        "Prediction": ["Malicious" if p==1 else "Benign" for p in y_pred]
    })
    if y_true is not None:
        results["Actual"] = ["Malicious" if t==1 else "Benign" for t in y_true]
        
    print(results.head(10).to_string())
    print("==========================================")

if __name__ == "__main__":
    if len(sys.argv) > 1:
        test_file = sys.argv[1]
    else:
        test_file = None
        
    test_model(test_file)
